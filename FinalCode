{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JMurciaa/AER850-Project-3/blob/main/FinalCode\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Juan Murcia\n",
        "#AER850 Project 3\n",
        "!pip install ultralytics\n",
        "!pip install opencv-python-headless matplotlib Pillow\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Verify if the file exists\n",
        "file_path = '/content/drive/MyDrive/data/motherboard_image.JPEG'\n",
        "if os.path.exists(file_path):\n",
        "    print(\"File found successfully!\")\n",
        "else:\n",
        "    print(\"File not found. Check the path and file name.\")\n",
        "\n",
        "\n",
        "#Step 1: Object Masking\n",
        "image_path = '/content/drive/MyDrive/data/motherboard_image.JPEG'\n",
        "image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.title(\"Original Image\")\n",
        "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "plt.show()\n",
        "\n",
        "#Greyscaling the Image and displaying it\n",
        "grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.title(\"Grayscale Image\")\n",
        "plt.imshow(grayscale_image, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "#Enhance Contrast before applying Gaussian Blur\n",
        "contrast_enhanced_image = cv2.equalizeHist(grayscale_image)\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.title(\"Contrast Enhanced Image\")\n",
        "plt.imshow(contrast_enhanced_image, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "#Applying Guassian Blur and Displaying Blurred Image\n",
        "blurred_image = cv2.GaussianBlur(contrast_enhanced_image, (5, 5), 0)\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.title(\"Blurred Image\")\n",
        "plt.imshow(blurred_image, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "#Thresholding\n",
        "_, thresholded_image = cv2.threshold(blurred_image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "#Cleaning\n",
        "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
        "cleaned_image = cv2.morphologyEx(thresholded_image, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "#Contours\n",
        "contours, _ = cv2.findContours(cleaned_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "filtered_contours = [c for c in contours if cv2.contourArea(c) > 50000]\n",
        "if not filtered_contours: raise ValueError(\"No significant contours found. Consider adjusting parameters.\")\n",
        "\n",
        "#Creating a Mask\n",
        "pcb_mask = np.zeros_like(grayscale_image)\n",
        "cv2.drawContours(pcb_mask, filtered_contours, -1, 255, cv2.FILLED)\n",
        "refinement_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (10, 10))\n",
        "refined_mask = cv2.erode(pcb_mask, refinement_kernel, iterations=1)\n",
        "\n",
        "#Extracting PCB\n",
        "extracted_pcb = cv2.bitwise_and(image, image, mask=refined_mask)\n",
        "x, y, w, h = cv2.boundingRect(max(filtered_contours, key=cv2.contourArea))\n",
        "cropped_pcb = extracted_pcb[y:y+h, x:x+w]\n",
        "\n",
        "#Displaying Results\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.title(\"Grayscale Image\")\n",
        "plt.imshow(cv2.cvtColor(grayscale_image, cv2.COLOR_GRAY2RGB))\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.title(\"Mask\")\n",
        "plt.imshow(refined_mask, cmap=\"gray\")\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.title(\"Extracted PCB\")\n",
        "plt.imshow(cv2.cvtColor(cropped_pcb, cv2.COLOR_BGR2RGB))\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "yi2GB1p9dU_w",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 2: YOLOv8 Training\n",
        "from ultralytics import YOLO\n",
        "\n",
        "\n",
        "# Load a pretrained YOLO model (recommended for training)\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Train the model\n",
        "dataset_config_path = '/content/drive/MyDrive/data/data.yaml'\n",
        "results = model.train(data=dataset_config_path, epochs=150, batch = 10, imgsz = 900, name='pcb identifier')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7EWxCc-TkBy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model's performance on the validation set\n",
        "results = model.val()\n",
        "\n"
      ],
      "metadata": {
        "id": "fuWk71QaiqNy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f11087e-96c5-48fb-945d-df7c5771c820",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.227 ðŸš€ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3008183 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Colab Notebooks/Project 3 Data/data/valid/labels.cache... 105 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 26, len(boxes) = 19108. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  18%|â–ˆâ–Š        | 2/11 [00:04<00:20,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING âš ï¸ NMS time limit 1.000s exceeded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  27%|â–ˆâ–ˆâ–‹       | 3/11 [00:08<00:24,  3.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING âš ï¸ NMS time limit 1.000s exceeded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 5/11 [00:25<00:36,  6.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING âš ï¸ NMS time limit 1.000s exceeded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 6/11 [00:38<00:41,  8.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING âš ï¸ NMS time limit 1.000s exceeded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:55<00:00,  5.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        105      19108      0.237      0.117     0.0646      0.036\n",
            "                Button        105         45          1          0          0          0\n",
            "             Capacitor        105       7251      0.158      0.129     0.0917     0.0396\n",
            "             Connector        105        659      0.156      0.361      0.149     0.0807\n",
            "                 Diode        105         53          0          0          0          0\n",
            "Electrolytic Capacitor        105        160      0.099      0.231      0.079     0.0497\n",
            "                    IC        105       1322      0.443      0.489      0.398      0.233\n",
            "              Inductor        105         45          1          0          0          0\n",
            "                   Led        105        127          0          0    0.00612    0.00423\n",
            "                  Pads        105        143          0          0    0.00143      0.001\n",
            "                  Pins        105        151     0.0644      0.238     0.0434      0.024\n",
            "              Resistor        105       8600      0.106     0.0342     0.0464     0.0224\n",
            "                Switch        105         28     0.0277     0.0357    0.00943    0.00642\n",
            "            Transistor        105        524      0.027    0.00382     0.0155    0.00696\n",
            "Speed: 1.6ms preprocess, 72.1ms inference, 0.0ms loss, 72.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/pcb identifier42\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 3: YOLOv8 Evaluation\n",
        "model.predict('/content/drive/MyDrive/data/evaluation/ardmega.jpg', save=True, imgsz=900, conf=0.5)\n",
        "model.predict('/content/drive/MyDrive/data/evaluation/arduno.jpg', save=True, imgsz=900, conf=0.5)\n",
        "model.predict('/content/drive/MyDrive/data/evaluation/rasppi.jpg', save=True, imgsz=900, conf=0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRDVJ8SAlB3n",
        "outputId": "08c9fc17-4002-40f3-87ae-57715ecc89a6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WARNING âš ï¸ imgsz=[900] must be multiple of max stride 32, updating to [928]\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/Project 3 Data/data/evaluation/ardmega.jpg: 832x928 4 Connectors, 2 ICs, 1 Switch, 27.5ms\n",
            "Speed: 7.0ms preprocess, 27.5ms inference, 3.9ms postprocess per image at shape (1, 3, 832, 928)\n",
            "Results saved to \u001b[1mruns/detect/pcb identifier43\u001b[0m\n",
            "\n",
            "WARNING âš ï¸ imgsz=[900] must be multiple of max stride 32, updating to [928]\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/Project 3 Data/data/evaluation/arduno.jpg: 640x928 4 Connectors, 1 IC, 37.4ms\n",
            "Speed: 4.4ms preprocess, 37.4ms inference, 6.5ms postprocess per image at shape (1, 3, 640, 928)\n",
            "Results saved to \u001b[1mruns/detect/pcb identifier44\u001b[0m\n",
            "\n",
            "WARNING âš ï¸ imgsz=[900] must be multiple of max stride 32, updating to [928]\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/Project 3 Data/data/evaluation/rasppi.jpg: 640x928 2 Capacitors, 3 Connectors, 7 ICs, 23.0ms\n",
            "Speed: 5.8ms preprocess, 23.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 928)\n",
            "Results saved to \u001b[1mruns/detect/pcb identifier45\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'Button', 1: 'Capacitor', 2: 'Connector', 3: 'Diode', 4: 'Electrolytic Capacitor', 5: 'IC', 6: 'Inductor', 7: 'Led', 8: 'Pads', 9: 'Pins', 10: 'Resistor', 11: 'Switch', 12: 'Transistor'}\n",
              " orig_img: array([[[154, 174, 191],\n",
              "         [164, 182, 199],\n",
              "         [165, 181, 198],\n",
              "         ...,\n",
              "         [139, 163, 183],\n",
              "         [132, 155, 177],\n",
              "         [129, 152, 174]],\n",
              " \n",
              "        [[154, 174, 191],\n",
              "         [159, 177, 194],\n",
              "         [164, 180, 197],\n",
              "         ...,\n",
              "         [135, 159, 179],\n",
              "         [130, 153, 175],\n",
              "         [128, 151, 173]],\n",
              " \n",
              "        [[151, 171, 189],\n",
              "         [155, 175, 193],\n",
              "         [152, 169, 188],\n",
              "         ...,\n",
              "         [127, 151, 173],\n",
              "         [124, 148, 170],\n",
              "         [123, 147, 169]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[138, 153, 172],\n",
              "         [145, 160, 179],\n",
              "         [138, 152, 174],\n",
              "         ...,\n",
              "         [126, 146, 164],\n",
              "         [108, 129, 150],\n",
              "         [111, 132, 153]],\n",
              " \n",
              "        [[138, 155, 174],\n",
              "         [153, 170, 189],\n",
              "         [144, 161, 180],\n",
              "         ...,\n",
              "         [135, 155, 173],\n",
              "         [117, 138, 159],\n",
              "         [111, 132, 153]],\n",
              " \n",
              "        [[140, 157, 176],\n",
              "         [152, 169, 188],\n",
              "         [147, 164, 183],\n",
              "         ...,\n",
              "         [132, 152, 170],\n",
              "         [106, 127, 148],\n",
              "         [118, 139, 160]]], dtype=uint8)\n",
              " orig_shape: (2000, 3008)\n",
              " path: '/content/drive/MyDrive/Colab Notebooks/Project 3 Data/data/evaluation/rasppi.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/pcb identifier45'\n",
              " speed: {'preprocess': 5.808591842651367, 'inference': 23.01192283630371, 'postprocess': 2.123117446899414}]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform object detection on an image using the model\n",
        "results = model(['/content/drive/MyDrive/data/evaluation/ardmega.jpg', '/content/drive/MyDrive/data/evaluation/arduno.jpg', '/content/drive/MyDrive/data/evaluation/rasppi.jpg'], save=True)  # return a list of Results objects\n",
        "res_plotted = results[0].plot()\n",
        "\n",
        "for result in results:\n",
        "    boxes = result.boxes.cpu().numpy()  # Boxes object for bbox outputs\n",
        "    masks = result.masks  # Masks object for segmentation masks outputs\n",
        "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
        "    probs = result.probs  # Probs object for classification outputs\n",
        "\n",
        "# Export the model to ONNX format\n",
        "success = model.export(format='onnx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xyt3ZgokkHi5",
        "outputId": "094a706b-df18-4252-ba5e-7af0884458e8",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 928x928 2 Capacitors, 9 Connectors, 4 ICs, 3 Resistors, 1 Switch, 1: 928x928 2 Capacitors, 7 Connectors, 1 Electrolytic Capacitor, 3 ICs, 1 Pins, 1 Resistor, 2: 928x928 10 Capacitors, 7 Connectors, 1 Electrolytic Capacitor, 13 ICs, 5 Resistors, 36.3ms\n",
            "Speed: 7.9ms preprocess, 12.1ms inference, 2.7ms postprocess per image at shape (1, 3, 928, 928)\n",
            "Results saved to \u001b[1mruns/detect/pcb identifier46\u001b[0m\n",
            "Ultralytics YOLOv8.0.227 ðŸš€ Python-3.10.12 torch-2.1.0+cu121 CPU (Intel Xeon 2.00GHz)\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/detect/pcb identifier4/weights/best.pt' with input shape (1, 3, 928, 928) BCHW and output shape(s) (1, 17, 17661) (6.0 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.15.0 opset 17...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 1.0s, saved as 'runs/detect/pcb identifier4/weights/best.onnx' (11.9 MB)\n",
            "\n",
            "Export complete (2.8s)\n",
            "Results saved to \u001b[1m/content/runs/detect/pcb identifier4/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=runs/detect/pcb identifier4/weights/best.onnx imgsz=928  \n",
            "Validate:        yolo val task=detect model=runs/detect/pcb identifier4/weights/best.onnx imgsz=928 data=/content/drive/MyDrive/Colab Notebooks/Project 3 Data/data/data.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        }
      ]
    }
  ]
}